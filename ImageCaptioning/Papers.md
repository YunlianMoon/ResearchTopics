# Image Captioning

### Paper

Deep visual-semantic alignments for generating image descriptions \[2015, CVPR, Andrej Karpathy\] \[[paper](https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Karpathy_Deep_Visual-Semantic_Alignments_2015_CVPR_paper.pdf)\]

Show and tell: A neural image caption generator \[2015, CVPR, Oriol Vinyals\] \[[paper](https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Vinyals_Show_and_Tell_2015_CVPR_paper.pdf)\]

Show, attend and tell: Neural image caption generation with visual attention \[2015, ICML, Kelvin Xu\] \[[paper](http://proceedings.mlr.press/v37/xuc15.pdf)\]

Teaching machines to describe images via natural language feedback \[2017, NIPS, Huan Ling\] \[[paper](http://www.cs.cmu.edu/~jeanoh/16-785/papers/ling-nips2017-nl-feedback.pdf)\]

Bottom-up and top-down attention for image captioning and visual question answering \[2018, CVPR, Peter Anderson\] \[[Paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Anderson_Bottom-Up_and_Top-Down_CVPR_2018_paper.pdf)\]
