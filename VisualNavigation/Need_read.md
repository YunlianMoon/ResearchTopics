# Papers

SplitNet: Sim2Sim and Task2Task Transfer for Embodied Visual Navigation \[2019, arxiv, Daniel Gordon\] \[[paper](https://arxiv.org/pdf/1905.07512.pdf)\]

Combining optimal control and learning for visual navigation in novel environments \[2019, arxiv, Somil Bansal\] \[[paper](https://arxiv.org/pdf/1903.02531.pdf)\]

A behavioral approach to visual navigation with graph localization networks \[2019, arxiv, Kevin Chen\] \[[paper](https://arxiv.org/pdf/1903.00445.pdf)\]

Learning to Learn How to Learn: Self-Adaptive Visual Navigation Using Meta-Learning \[2019, CVPR, Mitchell Wortsman\] \[[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Wortsman_Learning_to_Learn_How_to_Learn_Self-Adaptive_Visual_Navigation_Using_CVPR_2019_paper.pdf)\]

Conditional Driving from Natural Language Instructions

Two Body Problem: Collaborative Visual Task Completion

From recognition to cognition: Visual commonsense reasoning

Video Relationship Reasoning using Gated Spatio-Temporal Energy Graph

OK-VQA: A Visual Question Answering Benchmark Requiring External Knowledge

