# Papers

SplitNet: Sim2Sim and Task2Task Transfer for Embodied Visual Navigation \[2019, arxiv, Daniel Gordon\] \[[paper](https://arxiv.org/pdf/1905.07512.pdf)\]

Combining optimal control and learning for visual navigation in novel environments \[2019, arxiv, Somil Bansal\] \[[paper](https://arxiv.org/pdf/1903.02531.pdf)\]

A behavioral approach to visual navigation with graph localization networks \[2019, arxiv, Kevin Chen\] \[[paper](https://arxiv.org/pdf/1903.00445.pdf)\]

Learning to Learn How to Learn: Self-Adaptive Visual Navigation Using Meta-Learning \[2019, CVPR, Mitchell Wortsman\] \[[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Wortsman_Learning_to_Learn_How_to_Learn_Self-Adaptive_Visual_Navigation_Using_CVPR_2019_paper.pdf)\]

Conditional Driving from Natural Language Instructions

Two Body Problem: Collaborative Visual Task Completion

From recognition to cognition: Visual commonsense reasoning

Video Relationship Reasoning using Gated Spatio-Temporal Energy Graph

OK-VQA: A Visual Question Answering Benchmark Requiring External Knowledge

Transferring Common-Sense Knowledge for Object Detection

Learning cooperative visual dialog agents with deep reinforcement learning

Neural modular control for embodied question answering

Exploratory gradient boosting for reinforcement learning in complex domains

Deepdriving: Learning affordance for direct perception in autonomous driving

Learning transferable policies for monocular reactive mav control

Plato: Policy learning using adaptive trajectory optimization

RL: Fast Reinforcement Learning via Slow Reinforcement Learning

Playing doom with slam-augmented deep reinforcement learning

Unifying Map and Landmark Based Representations for Visual Navigation



