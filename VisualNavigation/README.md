# Visual Navigation using DRL

### Table of Contents
- Task
- Challenge
- Survey
- Paper
  - [map](https://github.com/YunlianMoon/ResearchTopics/blob/master/VisualNavigation/map.md)
  - [observation only](https://github.com/YunlianMoon/ResearchTopics/blob/master/VisualNavigation/observation_only.md)
  - [target driven](https://github.com/YunlianMoon/ResearchTopics/blob/master/VisualNavigation/target_driven.md)
  - [semantic](https://github.com/YunlianMoon/ResearchTopics/blob/master/VisualNavigation/semantic.md)
  - [instruction](https://github.com/YunlianMoon/ResearchTopics/blob/master/VisualNavigation/instruction.md)
  - [question](https://github.com/YunlianMoon/ResearchTopics/blob/master/VisualNavigation/question.md)
  
### Task

The goal of visual navigation is to move towards certain objects or regions of an environment.

A key challenge in navigation is generalizing to a scene that has not been observed during training, as the structure of the scene and appearance of objects are unfamiliar.

### Challenge
Imagine asking a home robot to go some place, in order to be successful, such an agent would need a range of artificial intelligence (AI) skills â€“ visual perception (to recognize objects, scenes, obstacles), language understanding (to translate questions and instructions into actions), and navigation of potentially novel environments (to move and find things in a changing world). 

### Survey

Probabilistic robotics \[2005, MIT press, Sebastian Thrun\] \[[Paper](http://home.deib.polimi.it/gini/robot/docs/Thrun.pdf)\]

Visual navigation for mobile robots: A survey \[2008, IORS, Bonin-Font\] \[[Paper](https://link.springer.com/content/pdf/10.1007%2Fs10846-008-9235-4.pdf)\]

A critical investigation of deep reinforcement learning for navigation \[2018, arxiv, Vikas Dhiman\] \[[Paper](https://arxiv.org/pdf/1802.02274.pdf)\]

On evaluation of embodied navigation agents \[2018, arxiv, Peter Anderson\] \[[Paper](https://arxiv.org/pdf/1807.06757.pdf)\]


